{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from os.path import isfile, isdir, join, split, splitext, exists\n",
    "from os import listdir, makedirs\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Declaration Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SAD(arr1, arr2):\n",
    "    \"\"\"Calculate sum of absolute distance\"\"\"\n",
    "    z = abs(arr1/100 - arr2/100)\n",
    "    z = z * 100\n",
    "    return np.sum(z)\n",
    "\n",
    "def calculate_SSD(arr1, arr2):\n",
    "    \"\"\"Calculate sum of squared distance\"\"\"\n",
    "    z = abs(arr1/100 - arr2/100)\n",
    "    z = z * 100\n",
    "    return np.sum(z**2)\n",
    "\n",
    "timer = []\n",
    "def stopwatch_start():\n",
    "    if len(timer) == 0:\n",
    "        timer.append(time.time())\n",
    "    else:\n",
    "        print(\"Stopwatch already started, please stop the stopwatch using stopwatch_stop() function\")\n",
    "\n",
    "def stopwatch_stop():\n",
    "    if len(timer) > 0:\n",
    "        return time.time() - timer.pop()\n",
    "    else:\n",
    "        print(\"Please start a stopwatch using time_start() function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require the following library:\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Receive np.array, show the image\n",
    "def show_image(arr, title=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plt.imshow(np.asarray(arr))\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Read all images and convert to grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train_image: 1322\n",
      "Total test_image: 1093\n",
      "Total image files found: 2415\n"
     ]
    }
   ],
   "source": [
    "my_path = \"CroppedYale/\"\n",
    "\n",
    "directories = [join(my_path, d) for d in listdir(my_path) if isdir(join(my_path, d))]\n",
    "image_files = [join(d, f) for d in directories for f in listdir(d) \n",
    "               if isfile(join(d, f)) and splitext(f)[-1] != \".bad\"]\n",
    "\n",
    "# Per question specified, take the first 35 as train_images and the rest as\n",
    "train_image = [join(d, f)for d in directories for n, f in enumerate(listdir(d)) \n",
    "               if isfile(join(d, f)) and n < 35 and splitext(f)[-1] != \".bad\"]\n",
    "test_image = [join(d, f)for d in directories for n, f in enumerate(listdir(d)) \n",
    "               if isfile(join(d, f)) and n >= 35 and splitext(f)[-1] != \".bad\"]\n",
    "\n",
    "print(\"Total train_image: {}\".format(len(train_image)))\n",
    "print(\"Total test_image: {}\".format(len(test_image)))\n",
    "print(\"Total image files found: {}\".format(len(image_files)))\n",
    "\n",
    "# print(\"{:^3} - {}\".format(\"#\", \"Filename\"))\n",
    "# [\"{:03} - {}\".format(n+1, f) for n, f in enumerate(image_files)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code within above cell is equal to the following code:\n",
    "```\n",
    "directories = []\n",
    "for d in listdir(my_path):\n",
    "    if isdir(join(my_path, d)):\n",
    "        directories.append(join(my_path, d))\n",
    "directories[0:5], len(directories)\n",
    "\n",
    "image_files = []\n",
    "for d in directories:\n",
    "    for f in listdir(d):\n",
    "        if isfile(join(d, f)):\n",
    "            image_files.append(join(d, f))\n",
    "image_files[0:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grayscale_path = \"CroppedYale_Grayscale/\"\n",
    "\n",
    "for n, d in enumerate(directories):\n",
    "    _d = d.split('/')\n",
    "    _dir = join(grayscale_path, _d[1])\n",
    "    if not exists(_dir):\n",
    "#         print(\"{} Not exist\".format(_dir))\n",
    "#         print(\"Creating directory {}\".format(_dir))\n",
    "        makedirs(_dir)\n",
    "        print(\"Created '{}' directory\\n\".format(_dir))\n",
    "    else:\n",
    "#         print(\"'{}' folder exist\".format(_dir))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code converts the images into grayscale images<br>\n",
    "Logical operations as following:\n",
    "1. `Line 3~5`: Since the program may takes some times and computational resources, we define a timer for measurement\n",
    "2. `Line 8~11`: Through the previous run, we found some images have .bad extension. We used `os.path.splitext` to filter out the extension of the file and `continue` the loop upon finding `.pgm` extension.\n",
    "3. `Line 13~17`: Since the grayscale images may already exists, we did a check-up before actually converting the images and save them into grayscale image\n",
    "4. `Line 19~22`: Open image, convert image into grayscale with `L` parameter, save it into `gray_img_name`, add `converted` counter by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415 of grayscale images already existed.\n",
      "Finished converting 0 images to grayscale image in 0.033s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "converted = 0\n",
    "file_existed = 0\n",
    "\n",
    "for i in image_files:\n",
    "    ext = splitext(i)\n",
    "    if ext[-1] != \".pgm\":\n",
    "        print(\"Excluding image {}\".format(i))\n",
    "        continue\n",
    "\n",
    "    img_name = i.split('/')\n",
    "    gray_img_name = join(grayscale_path, img_name[1], img_name[2])\n",
    "    if exists(gray_img_name):\n",
    "        file_existed = file_existed + 1\n",
    "        continue\n",
    "    \n",
    "    img = Image.open(i)\n",
    "    img = img.convert(\"L\")\n",
    "    img.save(gray_img_name)\n",
    "    converted = converted + 1\n",
    "print(\"{} of grayscale images already existed.\".format(file_existed))\n",
    "print(\"Finished converting {} images to grayscale image in {:.3f}s\".format(converted, time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Split the images into training set / test set\n",
    "- First 35 images as training, the rest 30 images as testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing up the first 35 identical person images as training image and the rest 30 images as testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_image): 1322\n",
      "len(test_image) : 1093\n"
     ]
    }
   ],
   "source": [
    "# train_image = image_files[:35]\n",
    "# test_image  = image_files[35:64]\n",
    "print(\"len(train_image): {}\\n\" \\\n",
    "      \"len(test_image) : {}\".format(len(train_image), len(test_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following part is not necessary\n",
    "Introduce two `np.array` variables as `train_arr` and `test_arr` to contain the array\n",
    "\n",
    "```\n",
    "train_arr = np.array([], ndmin=1, dtype=np.int64)\n",
    "test_arr = np.array([], ndmin=1, dtype=np.int64)\n",
    "\n",
    "start = time.time()\n",
    "for a_train_image in train_image:\n",
    "    train_arr = np.append(train_arr,\n",
    "                         np.array(Image.open(a_train_image)))\n",
    "print(\"Finished appending train_image to train_arr in {:.3f}s\".format(time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "for a_test_image in test_image:\n",
    "    test_arr = np.append(test_arr,\n",
    "                         np.array(Image.open(a_test_image)))\n",
    "print(\"Finished appending test_image to test_arr in {:.3f}s\".format(time.time() - start))\n",
    "\n",
    "print(\"train_arr shape : {}\".format(train_arr.shape))\n",
    "print(\"test_arr shape  : {}\".format(test_arr.shape))\n",
    "```\n",
    "Takes around 240s to append train_arr<br>\n",
    "Takes around 150s to append test_arr\n",
    "\n",
    "Example above does not use `np.ravel` on its implementation because `np.append` append values to the end of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gs_train_image: 1322\n",
      "Total gs_test_image : 1093\n"
     ]
    }
   ],
   "source": [
    "gs_train_image = [train.replace(\"CroppedYale\", \"CroppedYale_Grayscale\") for train in train_image]\n",
    "gs_test_image  = [test.replace(\"CroppedYale\", \"CroppedYale_Grayscale\") for test in test_image]\n",
    "\n",
    "print(\"Total gs_train_image: {}\".format(len(gs_train_image)))\n",
    "print(\"Total gs_test_image : {}\".format(len(gs_test_image)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring dictionary variables where the dictionary has a `key` with the **name of the test image** and the `value` representing a `list` with only two members. The first members is the `train_image` with the lowest `calculate_SAD` or lowest `calculate_SSD` score.\n",
    "\n",
    "```\n",
    "sad_score_dict[\"test_image_1\"] = [\"train_image_n\", 10]\n",
    "ssd_score_dict[\"test_image_1\"] = [\"train_image_n\", 10]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_score_dict = {}\n",
    "ssd_score_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code cell will run around 9~10hrs in Macbook Pro 15\" 2015\n",
    "The following code cell will be marked-down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print(\"Total gs_train_image: {}\".format(len(gs_train_image)))\n",
    "print(\"Total gs_test_image : {}\".format(len(gs_test_image)))\n",
    "\n",
    "stopwatch_stop()\n",
    "stopwatch_start()\n",
    "\n",
    "sad_score_dict = {}\n",
    "ssd_score_dict = {}\n",
    "\n",
    "for i, test in enumerate(gs_test_image):\n",
    "    print(\"\\nTest image {}\\t\".format(i))\n",
    "    sad_score_dict[test] = {}\n",
    "    ssd_score_dict[test] = {}\n",
    "    min_sad_image = \"\"\n",
    "    for n, train in enumerate(gs_train_image):\n",
    "        if n % 50 == 0:\n",
    "            print(\"\\tProgress: comparing with train_image {:>4}.....\".format(n))\n",
    "        te = np.array(Image.open(test), dtype=np.int64)\n",
    "        tr = np.array(Image.open(train), dtype=np.int64)\n",
    "        \n",
    "        # Set an initial value for the SAD/SSD score and assign the first train image\n",
    "        if n==0:\n",
    "            sad_score_dict[test] = {train: calculate_SAD(te, tr)}\n",
    "            ssd_score_dict[test] = {train: calculate_SSD(te, tr)}\n",
    "            min_sad_image = train\n",
    "            print(\"\\t\\tSetting initial SAD/SSD value...\")\n",
    "            print(\"\\t\\tKey   : {}\".format(sad_score_dict[test].keys()[0]))\n",
    "            print(\"\\t\\tValue : {}\".format(sad_score_dict[test].keys()[0]))\n",
    "            continue\n",
    "        \n",
    "        # Comparing the current image with the minimum SAD/SSD score\n",
    "        _sad = calculate_SAD(te, tr)\n",
    "        if _sad < sad_score_dict[test][min_sad_image]:\n",
    "            print(\"\\t\\tFound a lower SAD/SSD value...\")\n",
    "            sad_score_dict[test] = {train: _sad}\n",
    "            ssd_score_dict[test] = {train: calculate_SSD(te, tr)}\n",
    "            min_sad_image = train\n",
    "            print(\"\\t\\tUpdating SAD/SSD value...\")\n",
    "            print(\"\\t\\tKey   : {}\".format(sad_score_dict[test].keys()[0]))\n",
    "            print(\"\\t\\tValue : {}\".format(sad_score_dict[test].keys()[0]))\n",
    "\n",
    "print(\"Total elapsed time: {}\".format(stopwatch_stop()))\n",
    "\n",
    "# Time elapsed: 34618.692924\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code writes all the SAD/SSD calculation into JSON file\n",
    "It will be marked down since the cell above is marked-down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Writing to JSON file to eliminate the need for calculation\n",
    "\n",
    "stopwatch_stop()\n",
    "stopwatch_start()\n",
    "with open('sad_result.json', 'w') as fp:\n",
    "    json.dump(sad_score_dict, fp)\n",
    "print(\"Writing sad_result.json finished in {:.3f}\".format(stopwatch_stop()))\n",
    "\n",
    "stopwatch_start()\n",
    "with open('ssd_result.json', 'w') as fp:\n",
    "    json.dump(ssd_score_dict, fp)\n",
    "print(\"Writing ssd_result.json finished in {:.3f}\".format(stopwatch_stop()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading through JSON.files written on previous calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_score_dict = json.load(open('sad_result.json'))\n",
    "ssd_score_dict = json.load(open('ssd_result.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   u'CroppedYale_Grayscale/yaleB36/yaleB36_P00A-060E-20.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB36/yaleB36_P00A-070E+00.pgm': 282300}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB35/yaleB35_P00A-110E+65.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB32/yaleB32_P00A-110E+65.pgm': 13900}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB25/yaleB25_P00A+010E-20.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB25/yaleB25_P00A+025E+00.pgm': 714200}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB04/yaleB04_P00A+110E+40.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB01/yaleB01_P00A+110E+40.pgm': 239400}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB06/yaleB06_P00A-010E-20.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB06/yaleB06_P00A+000E-20.pgm': 512200})]\n",
      "[   (   u'CroppedYale_Grayscale/yaleB36/yaleB36_P00A-060E-20.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB36/yaleB36_P00A-070E+00.pgm': 28290000}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB35/yaleB35_P00A-110E+65.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB32/yaleB32_P00A-110E+65.pgm': 1390000}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB25/yaleB25_P00A+010E-20.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB25/yaleB25_P00A+025E+00.pgm': 71440000}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB04/yaleB04_P00A+110E+40.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB01/yaleB01_P00A+110E+40.pgm': 24480000}),\n",
      "    (   u'CroppedYale_Grayscale/yaleB06/yaleB06_P00A-010E-20.pgm',\n",
      "        {   u'CroppedYale_Grayscale/yaleB06/yaleB06_P00A+000E-20.pgm': 51280000})]\n"
     ]
    }
   ],
   "source": [
    "pprint(sad_score_dict.items()[0:5], indent=4)\n",
    "pprint(ssd_score_dict.items()[0:5], indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the accuracy\n",
    "\n",
    "```\n",
    "# pseudocode\n",
    "    accuracy = how many test correctly labeled / how many test images\n",
    "\n",
    "# algorithm\n",
    "    1. check if the test's key == test's value[0], where value[0] is the train_image and value[1] is its SAD/SSD score\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAD correct :   686 SAD accuracy : 0.62763\n",
      "\n",
      "SSD correct :   686 SSD accuracy : 0.62763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sad_correct = 0\n",
    "ssd_correct = 0\n",
    "total_test_images = len(test_image)\n",
    "for k in sad_score_dict.keys():            # k stands for key\n",
    "    for pk in sad_score_dict[k].keys():    # pk stands predicted key\n",
    "        if k.split('/')[1] in pk:\n",
    "            sad_correct += 1\n",
    "\n",
    "for k in ssd_score_dict.keys():            # k stands for key\n",
    "    for pk in ssd_score_dict[k].keys():    # pk stands predicted key\n",
    "        if k.split('/')[1] in pk:\n",
    "            ssd_correct += 1\n",
    "\n",
    "print(\"SAD correct : {:>5} SAD accuracy : {:>.5f}\\n\".format(sad_correct, 1. * sad_correct / total_test_images))\n",
    "print(\"SSD correct : {:>5} SSD accuracy : {:>.5f}\\n\".format(ssd_correct, 1. * ssd_correct / total_test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
